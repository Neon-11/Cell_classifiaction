{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "791063ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 21:50:19.608271: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self or lab: self\n",
      "using neo11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization\n",
    "from tensorflow.keras.layers import ReLU, AvgPool2D, Flatten, Dense\n",
    "import PIL\n",
    "from PIL import ImageOps\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.image import imread, imsave\n",
    "%matplotlib inline\n",
    "\n",
    "# workstation used\n",
    "ans = input('self or lab: ')\n",
    "if ans == 'self':\n",
    "    idi = '/home/neo11/Documents'\n",
    "    print('using neo11')\n",
    "else:\n",
    "    idi = '/home/melcher/Documents/Nihal'\n",
    "    print('using melcher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6431c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = imread('train_cell.png')\n",
    "img = np.array(a)\n",
    "img = np.mean(img, -1)\n",
    "\n",
    "U, S, VT = np.linalg.svd(img)\n",
    "w = 2.8525 # beta = 1\n",
    "\n",
    "s = S\n",
    "sigma = np.median(s)\n",
    "s.setflags(write = 1)\n",
    "\n",
    "tau = sigma*w\n",
    "\n",
    "for i in range(S.shape[0]):\n",
    "    if s[i] < tau:\n",
    "        s[i] = 0\n",
    "\n",
    "n= 0\n",
    "for j in s:\n",
    "    if j == 0:\n",
    "        print(n)\n",
    "        break\n",
    "    else:\n",
    "        n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635af313",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = imread('train_comp.png')\n",
    "img = np.array(a)\n",
    "img = np.mean(img, -1)\n",
    "\n",
    "U, S, VT = np.linalg.svd(img)\n",
    "w = 2.8525 # beta = 1\n",
    "\n",
    "s = S\n",
    "sigma = np.median(s)\n",
    "s.setflags(write = 1)\n",
    "\n",
    "tau = sigma*w\n",
    "\n",
    "for i in range(S.shape[0]):\n",
    "    if s[i] < tau:\n",
    "        s[i] = 0\n",
    "dataset_20722\n",
    "n= 0\n",
    "for j in s:\n",
    "    if j == 0:\n",
    "        print(n)\n",
    "        break\n",
    "    else:\n",
    "        n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd86e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since coffienct of the noise distribution is not know \n",
    "# using the 2nd method from IEEE 2014 SVD paper\n",
    "class preprocessing():\n",
    "    def __init__(self, input_di, output_di, ri):\n",
    "        self.ri = ri\n",
    "        self.d1 = input_di\n",
    "        self.d2 = output_di\n",
    "        self.arr = []\n",
    "        self.w = 2.8525\n",
    "        # we could add the genralized omega function but for our case beta = 1, and hence the value w = 2.8525 \n",
    "        self.s_m = 0\n",
    "        self.tau = 0\n",
    "        self.r = 0\n",
    "        self.i = 0\n",
    "        self.original = []\n",
    "        for j in os.listdir(self.d1):\n",
    "            img = image.load_img(self.d1 + '/' + j)\n",
    "            img = np.mean(np.array(img), -1)\n",
    "            img = img/255\n",
    "            U, S, VT = np.linalg.svd(img)\n",
    "            s = S\n",
    "            self.s_m = np.median(s)\n",
    "            s.setflags(write =1)\n",
    "            self.tau = self.s_m*self.w\n",
    "            \n",
    "            for i in range(S.shape[0]):\n",
    "                if s[i] < self.tau:\n",
    "                    s[i] = 0\n",
    "            \n",
    "            r = 0\n",
    "            for j in s:\n",
    "                if j == 0:\n",
    "                    break\n",
    "                else:\n",
    "                    r = r + 1\n",
    "            \n",
    "            X = U[:,self.ri:r] @ np.diag(S[self.ri:r]) @ VT[self.ri:r,:]\n",
    "            self.arr.append(X)\n",
    "            self.original.append(img)\n",
    "        \n",
    "        self.arr = np.array(self.arr)\n",
    "        self.original = np.array(self.original)\n",
    "        print('pre-processing completed')\n",
    "        print('initial parameter: ri = ' + str(ri))\n",
    "    \n",
    "    def original_arr(self):\n",
    "        return self.original\n",
    "    \n",
    "    def converted_arr(self):\n",
    "        return self.arr\n",
    "    \n",
    "    def noise_arr(self):\n",
    "        noise = self.original - self.arr \n",
    "        return noise\n",
    "    \n",
    "    def save_img(self):\n",
    "        for arr in self.arr:\n",
    "            self.i = self.i + 1\n",
    "            loc = os.path.join(self.d2 , \"svd\" +str(self.i) + '.png')\n",
    "            mpimg.imsave(loc, arr, cmap ='gray')\n",
    "        print('converted images saved in the second directory')\n",
    "        print('please check the directory...')\n",
    "    \n",
    "    def print_converted_img(self):\n",
    "        print('converted images')\n",
    "        for arr in self.arr:\n",
    "            plt.imshow(arr , cmap= 'gray')\n",
    "            plt.show()\n",
    "    \n",
    "    def print_noise_img(self):\n",
    "        print('noise as images')\n",
    "        noise = self.original - self.arr\n",
    "        for arr in noise:\n",
    "            plt.imshow(arr , cmap= 'gray')\n",
    "            plt.show()\n",
    "\n",
    "    def random_dataset_generator(self, f, train_dir, test_dir):\n",
    "        n = self.arr.shape[0]\n",
    "        n1 = int(f*n)\n",
    "        arr_list = [v for v in range(0,n)]\n",
    "        rand1 = list(random.sample(range(0, n), n - n1))\n",
    "        rand2 = list(set(arr_list) - set(rand1))\n",
    "        i = 0 \n",
    "        for i in range(len(rand1)):\n",
    "            arr = self.arr[rand1[i]]\n",
    "            i = i + 1\n",
    "            loc = os.path.join(train_dir , \"svd\" +str(i) + '.png')\n",
    "            mpimg.imsave(loc, arr, cmap ='gray')\n",
    "        \n",
    "        print('converted images saved in the train directory')\n",
    "        \n",
    "        i = 0\n",
    "        for i in range(len(rand2)):\n",
    "            arr = self.arr[rand2[i]]\n",
    "            i = i + 1\n",
    "            loc = os.path.join(test_dir , \"svd\" +str(i) + '.png')\n",
    "            mpimg.imsave(loc, arr, cmap ='gray')\n",
    "        \n",
    "        print('converted images saved in the test directory')\n",
    "        print('please check the directories...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9512109e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-processing completed\n",
      "initial parameter: ri = 0\n",
      "converted images saved in the train directory\n",
      "converted images saved in the test directory\n",
      "please check the directories...\n"
     ]
    }
   ],
   "source": [
    "d1 = '/home/neo11/Documents/ML in microfluids/main dataset/compiled/Cell'\n",
    "d2 = ''\n",
    "d_train = '/home/neo11/Documents/ML in microfluids/main dataset/svd_compiled/train/Cell' \n",
    "d_test = '/home/neo11/Documents/ML in microfluids/main dataset/svd_compiled/test/cell'\n",
    "\n",
    "a = preprocessing(d1, d2, 0)\n",
    "\n",
    "a.random_dataset_generator(0.425, d_train, d_test) # for saving the images to the second directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a9e39b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-processing completed\n",
      "initial parameter: ri = 0\n",
      "converted images saved in the second directory\n",
      "please check the directory...\n"
     ]
    }
   ],
   "source": [
    "di = idi + '/ML in microfluids/main dataset/cell_test'\n",
    "do = idi + '/ML in microfluids/main dataset/cell_svd_test'\n",
    "\n",
    "a = preprocessing(di, do, 0)\n",
    "\n",
    "a.save_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f7d643",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a.converted_arr()[1], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f30457",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a.original_arr()[1], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3567ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a.noise_arr()[1], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7103eda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ri =0\n",
    "np.mean(abs(a.noise_arr()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27cb35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ri = 3\n",
    "np.mean(abs(a.noise_arr()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d5012",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread('train_cell.png')\n",
    "img = np.array(img)\n",
    "img = np.mean(img, -1)\n",
    "img = img/255\n",
    "\n",
    "U, S, VT = np.linalg.svd(img)\n",
    "\n",
    "r1 = 3\n",
    "for r in range(r1+1,43):\n",
    "    X = U[:,r1:r] @ np.diag(S[r1:r]) @ VT[r1:r,:]\n",
    "    plt.imshow(X , cmap = 'gray')\n",
    "    plt.title('rank = ' + str(r1) + ' to rank = ' + str(r))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cc8bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread('train_comp.png')\n",
    "img = np.array(img)\n",
    "img = np.mean(img, -1)\n",
    "img = img/255\n",
    "\n",
    "U, S, VT = np.linalg.svd(img)\n",
    "\n",
    "r1 = 3\n",
    "for r in range(r1+1,40):\n",
    "    X = U[:,r1:r] @ np.diag(S[r1:r]) @ VT[r1:r,:]\n",
    "    plt.imshow(X , cmap = 'gray')\n",
    "    plt.title('rank = ' + str(r1) + ' to rank = ' + str(r))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e755c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread('train_cell.png')\n",
    "img = np.array(img)\n",
    "img = np.mean(img, -1)\n",
    "img = img/255\n",
    "\n",
    "U, S, VT = np.linalg.svd(img)\n",
    "\n",
    "r1 = 0\n",
    "r = 30\n",
    "\n",
    "X = U[:,r1:r] @ np.diag(S[r1:r]) @ VT[r1:r,:]\n",
    "plt.imshow(255*X , cmap = 'gray')\n",
    "plt.title('rank = ' + str(r))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92af15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread('train_comp.png')\n",
    "img = np.array(img)\n",
    "img = np.mean(img, -1)\n",
    "img = img/255\n",
    "\n",
    "U, S, VT = np.linalg.svd(img)\n",
    "\n",
    "r1 = 0\n",
    "r = 43\n",
    "\n",
    "X = U[:,r1:r] @ np.diag(S[r1:r]) @ VT[r1:r,:]\n",
    "plt.imshow(255*X , cmap = 'gray')\n",
    "plt.title('rank = ' + str(r))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e748ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class testdata():\n",
    "    def __init__(self, di_source, di_save):\n",
    "        self.d1 = di_source\n",
    "        self.d2 = di_save\n",
    "        self.li = os.listdir(self.d1)\n",
    "        \n",
    "    def save(self, n):\n",
    "        self.newli = []\n",
    "        self.n = n\n",
    "        self.l = random.sample(self.li, self.n)\n",
    "        for j in self.l:\n",
    "            img = image.load_img(self.d1 + '/' + j)\n",
    "            img = np.mean(np.array(img), -1)\n",
    "            img = img/255\n",
    "            self.newli.append(img)\n",
    "        self.newli = np.array(self.newli)\n",
    "        self.i = 1\n",
    "        for arr in self.newli:\n",
    "            loc = os.path.join(self.d2 , \"svd\" + str(self.i) + '.png')\n",
    "            mpimg.imsave(loc, arr, cmap ='gray')\n",
    "            self.i = self.i + 1\n",
    "        print('images saved at dir = ' + self.d2)\n",
    "        \n",
    "    def notused():\n",
    "        li = list(self.newli)\n",
    "        self.nli = [x for x in self.li if x not in self.newli]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f50000",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = idi + '/ML in microfluids/dataset/train/Cell'\n",
    "save_dir = idi + '/ML in microfluids/'\n",
    "\n",
    "testdata(img_dir, save_dir).save(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bcb91b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
